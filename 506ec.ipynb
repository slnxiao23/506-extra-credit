{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading Data...\n",
      "Step 2: Feature Engineering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/h0b2jqh116v87hw1qyyfsp500000gn/T/ipykernel_5437/3356500348.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_set[f'{column}_fraud_rate'].fillna(train_set['is_fraud'].mean(), inplace=True)\n",
      "/var/folders/jr/h0b2jqh116v87hw1qyyfsp500000gn/T/ipykernel_5437/3356500348.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_set[f'{column}_fraud_rate'].fillna(train_set['is_fraud'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Setting up Cross-Validation...\n",
      "    Training Fold 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LGBMClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_idx], y\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[1;32m     99\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlgb_params)\n\u001b[0;32m--> 100\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m out_of_fold_preds[val_idx] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    103\u001b[0m test_predictions\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: LGBMClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "\n",
    "def calculate_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Vectorized Haversine Distance Calculation using Numpy.\"\"\"\n",
    "    R = 6371  # Radius of Earth in km\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    delta_lat = lat2 - lat1\n",
    "    delta_lon = lon2 - lon1\n",
    "    a = np.sin(delta_lat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(delta_lon / 2.0)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def generate_time_attributes(data):\n",
    "    \"\"\"Generate cyclic time features.\"\"\"\n",
    "    data['timestamp'] = pd.to_datetime(data['trans_date'] + ' ' + data['trans_time'])\n",
    "    data['hour'] = data['timestamp'].dt.hour\n",
    "    data['weekday'] = data['timestamp'].dt.dayofweek\n",
    "    data['hour_sine'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "    data['hour_cosine'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "    return data\n",
    "\n",
    "def compute_distance_feature(data):\n",
    "    \"\"\"Add distance column using vectorized Haversine calculation.\"\"\"\n",
    "    data['distance_km'] = calculate_haversine(data['lat'], data['long'], data['merch_lat'], data['merch_long'])\n",
    "    return data\n",
    "\n",
    "def frequency_encoder(train_set, test_set, column):\n",
    "    \"\"\"Apply frequency encoding to a column.\"\"\"\n",
    "    freq_map = train_set[column].value_counts().to_dict()\n",
    "    train_set[f'{column}_freq'] = train_set[column].map(freq_map)\n",
    "    test_set[f'{column}_freq'] = test_set[column].map(freq_map).fillna(0)\n",
    "    return train_set, test_set\n",
    "\n",
    "def encode_fraud_rate(train_set, test_set, column):\n",
    "    \"\"\"Calculate fraud rate for a given column and merge it into datasets.\"\"\"\n",
    "    fraud_rate = train_set.groupby(column)['is_fraud'].mean().rename(f'{column}_fraud_rate')\n",
    "    train_set = train_set.merge(fraud_rate, on=column, how='left')\n",
    "    test_set = test_set.merge(fraud_rate, on=column, how='left')\n",
    "    test_set[f'{column}_fraud_rate'].fillna(train_set['is_fraud'].mean(), inplace=True)\n",
    "    return train_set, test_set\n",
    "\n",
    "print(\"Step 1: Loading Data...\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Step 2: Feature Engineering...\")\n",
    "train_df = generate_time_attributes(train_df)\n",
    "test_df = generate_time_attributes(test_df)\n",
    "\n",
    "train_df = compute_distance_feature(train_df)\n",
    "test_df = compute_distance_feature(test_df)\n",
    "\n",
    "# Frequency encoding for categorical features\n",
    "for feature in ['merchant', 'category', 'job']:\n",
    "    train_df, test_df = frequency_encoder(train_df, test_df, feature)\n",
    "\n",
    "# Fraud rate encoding for selected columns\n",
    "for feature in ['merchant', 'category']:\n",
    "    train_df, test_df = encode_fraud_rate(train_df, test_df, feature)\n",
    "\n",
    "# Drop irrelevant features\n",
    "drop_columns = ['trans_num', 'trans_date', 'trans_time', 'timestamp', 'id']\n",
    "X = train_df.drop(columns=['is_fraud'] + drop_columns, errors='ignore')\n",
    "y = train_df['is_fraud']\n",
    "test_ids = test_df['id']\n",
    "X_test = test_df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "# Handle missing values\n",
    "X.fillna(-1, inplace=True)\n",
    "X_test.fillna(-1, inplace=True)\n",
    "\n",
    "print(\"Step 3: Setting up Cross-Validation...\")\n",
    "n_folds = 5\n",
    "kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "lgb_params = {'n_estimators': 500, 'learning_rate': 0.03, 'num_leaves': 31, 'random_state': 42, 'class_weight': 'balanced'}\n",
    "\n",
    "# Cross-validation training\n",
    "out_of_fold_preds = np.zeros(len(X))\n",
    "test_predictions = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"    Training Fold {fold + 1}\")\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**lgb_params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='f1')\n",
    "    \n",
    "    out_of_fold_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_predictions.append(model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"Step 4: Finding Best Threshold...\")\n",
    "best_threshold, best_f1 = 0.5, 0\n",
    "for threshold in np.linspace(0.01, 0.99, 100):\n",
    "    preds = (out_of_fold_preds >= threshold).astype(int)\n",
    "    score = f1_score(y, preds)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(\"Step 5: Generating Final Predictions...\")\n",
    "final_test_preds = (np.mean(test_predictions, axis=0) >= best_threshold).astype(int)\n",
    "\n",
    "# Graph Analysis: Feature Importance\n",
    "print(\"Step 6: Plotting Feature Importance...\")\n",
    "lgb.plot_importance(model, max_num_features=10)\n",
    "plt.title(\"Top 10 Features by Importance\")\n",
    "plt.show()\n",
    "\n",
    "# Save Submission\n",
    "submission = pd.DataFrame({'id': test_ids, 'is_fraud': final_test_preds})\n",
    "submission.to_csv('my_submission.csv', index=False)\n",
    "print(f\"Best Threshold from CV: {best_threshold:.3f}, Best OOF F1-score: {best_f1:.5f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
